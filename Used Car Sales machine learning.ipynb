{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used car sales machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data and split into train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 544\n",
      "Number of rows: 316984\n",
      "\n",
      "\n",
      "Train size = 190190\n",
      "Validation size = 63397\n",
      "Test size = 63397\n"
     ]
    }
   ],
   "source": [
    "##Load in cleaned data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cars = pd.read_csv('cleaned_vehicles.csv')\n",
    "\n",
    "print(\"Number of features: \" +str(len(cars.columns)))\n",
    "print(\"Number of rows: \"+str(len(cars)))\n",
    "print(\"\\n\")\n",
    "\n",
    "##Shuffle dataset\n",
    "cars = cars.sample(frac=1, random_state=42)\n",
    "\n",
    "##Split into train, test and validation (60%, 20%, 20%)\n",
    "train, validation, test = np.split(cars,  [int(.6*len(cars)), int(.8*len(cars))])\n",
    "\n",
    "print(\"Train size = \"+str(len(train)))\n",
    "print(\"Validation size = \"+str(len(validation)))\n",
    "print(\"Test size = \"+str(len(test)))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split target variable from inputs\n",
    "trainX = train.drop(['price'], axis=1)\n",
    "trainY = train['price']\n",
    "\n",
    "validX = validation.drop(['price'], axis=1)\n",
    "validY = validation['price']\n",
    "\n",
    "testX = test.drop(['price'], axis=1)\n",
    "testY = test['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try many quick and dirty models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (with different regularizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####Normal Linear Regression######\n",
      "Train MSE: 0.004796721613369497\n",
      "Validation MSE: 2.7195634889375144e+16\n",
      "Test MSE: 0.00468055822057678\n",
      "\n",
      "\n",
      "#####LASSO Linear Regression######\n",
      "Train MSE: 0.01141967740157115\n",
      "Validation MSE: 0.01138012881093592\n",
      "Test MSE: 0.011502384297039293\n",
      "\n",
      "\n",
      "#####RIDGE Linear Regression######\n",
      "Train MSE: 0.004796191360930326\n",
      "Validation MSE: 0.004755812989821801\n",
      "Test MSE: 0.004680225184993724\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "##Normal linear regression\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(trainX, trainY)\n",
    "trainPredict = reg.predict(trainX)\n",
    "validPredict = reg.predict(validX)\n",
    "testPredict = reg.predict(testX)\n",
    "\n",
    "print(\"#####Normal Linear Regression######\")\n",
    "print(\"Train MSE: \"+str(mean_squared_error(trainY, trainPredict)))\n",
    "print(\"Validation MSE: \"+str(mean_squared_error(validY, validPredict)))\n",
    "print(\"Test MSE: \"+str(mean_squared_error(testY, testPredict)))\n",
    "print('\\n')\n",
    "\n",
    "##Linear regression with L1 (LASSO) regulariser\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "lasso.fit(trainX, trainY)\n",
    "trainPredict = lasso.predict(trainX)\n",
    "validPredict = lasso.predict(validX)\n",
    "testPredict = lasso.predict(testX)\n",
    "\n",
    "print(\"#####LASSO Linear Regression######\")\n",
    "print(\"Train MSE: \"+str(mean_squared_error(trainY, trainPredict)))\n",
    "print(\"Validation MSE: \"+str(mean_squared_error(validY, validPredict)))\n",
    "print(\"Test MSE: \"+str(mean_squared_error(testY, testPredict)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "##Linear regression with L2 (RIDGE) regulariser\n",
    "ridge = linear_model.Ridge(alpha=.5)\n",
    "ridge.fit(trainX, trainY)\n",
    "trainPredict = ridge.predict(trainX)\n",
    "validPredict = ridge.predict(validX)\n",
    "testPredict = ridge.predict(testX)\n",
    "\n",
    "print(\"#####RIDGE Linear Regression######\")\n",
    "print(\"Train MSE: \"+str(mean_squared_error(trainY, trainPredict)))\n",
    "print(\"Validation MSE: \"+str(mean_squared_error(validY, validPredict)))\n",
    "print(\"Test MSE: \"+str(mean_squared_error(testY, testPredict)))\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVM/support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging (Random Forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####Baggin (Random Forests) ######\n",
      "Train MSE: 0.006740794348262127\n",
      "Validation MSE: 0.00675701825125138\n",
      "Test MSE: 0.0067154156759958936\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randForestReg = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "randForestReg.fit(trainX, trainY)\n",
    "trainPredict = randForestReg.predict(trainX)\n",
    "validPredict = randForestReg.predict(validX)\n",
    "testPredict = randForestReg.predict(testX)\n",
    "\n",
    "print(\"#####Bagging (Random Forests) ######\")\n",
    "print(\"Train MSE: \"+str(mean_squared_error(trainY, trainPredict)))\n",
    "print(\"Validation MSE: \"+str(mean_squared_error(validY, validPredict)))\n",
    "print(\"Test MSE: \"+str(mean_squared_error(testY, testPredict)))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting (Adaboost and XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####Boosting (Adaboost) ######\n",
      "Train MSE: 0.008977221213093786\n",
      "Validation MSE: 0.008998580402742458\n",
      "Test MSE: 0.008964786268583625\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####Boosting (XGBoost) ######\n",
      "Train MSE: 0.0024938097377222683\n",
      "Validation MSE: 0.0028280594495580795\n",
      "Test MSE: 0.0027646131095732675\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "ada = AdaBoostRegressor()\n",
    "ada.fit(trainX, trainY)\n",
    "trainPredict = ada.predict(trainX)\n",
    "validPredict = ada.predict(validX)\n",
    "testPredict = ada.predict(testX)\n",
    "\n",
    "print(\"#####Boosting (Adaboost) ######\")\n",
    "print(\"Train MSE: \"+str(mean_squared_error(trainY, trainPredict)))\n",
    "print(\"Validation MSE: \"+str(mean_squared_error(validY, validPredict)))\n",
    "print(\"Test MSE: \"+str(mean_squared_error(testY, testPredict)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "xgboost = XGBRegressor()\n",
    "xgboost.fit(trainX, trainY)\n",
    "trainPredict = xgboost.predict(trainX)\n",
    "validPredict = xgboost.predict(validX)\n",
    "testPredict = xgboost.predict(testX)\n",
    "\n",
    "print(\"#####Boosting (XGBoost) ######\")\n",
    "print(\"Train MSE: \"+str(mean_squared_error(trainY, trainPredict)))\n",
    "print(\"Validation MSE: \"+str(mean_squared_error(validY, validPredict)))\n",
    "print(\"Test MSE: \"+str(mean_squared_error(testY, testPredict)))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
